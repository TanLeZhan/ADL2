{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344fa996",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "raw_dataset = pd.read_csv(\"./data/processed_data_encoded.csv\") #data has X and Y, community 0-9\n",
    "raw_dataset = raw_dataset.drop(columns=[\"BMI\"])\n",
    "Y = pd.DataFrame(raw_dataset[\"DR\"])\n",
    "# Slice your data\n",
    "\n",
    "\n",
    "X_FOR_FOLDS, X_FINAL_TEST, Y_FOR_FOLDS, Y_FINAL_TEST = train_test_split(X, Y, test_size=0.1, random_state=random_state, stratify=Y)\n",
    "df = pd.concat([X_FOR_FOLDS, Y_FOR_FOLDS], axis=1)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c6d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def Outlier_Removal(df_train, OD_majority, OD_minority): \n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    # Use the original encoded single column name here\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    y_col = 'DR'\n",
    "\n",
    "    print(\"Original class distribution:\",df[y_col].value_counts())\n",
    "    assert y_col in df_train.columns, f\"'{y_col}' column is missing in the DataFrame.\"\n",
    "    \n",
    "    #* OUTLIER DETECTION START\n",
    "    available_cont_cols = [col for col in cont_cols if col in df.columns]\n",
    "    df_majority = df[df[y_col] == 0].copy()\n",
    "    df_minority = df[df[y_col] == 1].copy()\n",
    "    if OD_majority is not None:\n",
    "        outliers_majority = OD_majority.fit_predict(df_majority[available_cont_cols])\n",
    "        df_majority = df_majority[outliers_majority == 1]\n",
    "        print(f\"After OD, majority: {len(df_majority)}\")\n",
    "    if OD_minority is not None:\n",
    "        outliers_minority = OD_minority.fit_predict(df_minority[available_cont_cols])\n",
    "        df_minority = df_minority[outliers_minority == 1]\n",
    "        print(f\"After OD, minority: {len(df_minority)}\")\n",
    "    df_after_OD = pd.concat([df_majority, df_minority], ignore_index=True)\n",
    "    #* OUTLIER DETECTION END - df_after_OD is the new df\n",
    "    return df_after_OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4f97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf15b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sdv\n",
    "from sdv.metadata import Metadata\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.single_table import TVAESynthesizer\n",
    "from sdv.sampling import Condition\n",
    "\n",
    "def Synthetic_Data_Generator(df_train, synthesizer = \"TVAE\", conditions = None, epochs = 200, batch_size = 512, n_synthetic_data = 1000): \n",
    "    \"\"\"Conditions: \"balanced\" or None\"\"\"\n",
    "    metadata = Metadata.detect_from_dataframe(data=df_train)\n",
    "    metadata.validate()\n",
    "    metadata.visualize()\n",
    "    #* Synthetic Data generation conditions\n",
    "    condition_list = []\n",
    "    if conditions == \"balanced\":\n",
    "        Balanced = Condition(\n",
    "                            num_rows=df_train[df_train['DR'] == 0].shape[0],\n",
    "                            column_values={'DR': '1'}\n",
    "                            )\n",
    "        print(\"Balancing condition applied: adding DR=1 samples only\")\n",
    "        condition_list.append(Balanced)\n",
    "    elif conditions == None:\n",
    "        synthetic_data_count = Condition(\n",
    "                            num_rows=n_synthetic_data,\n",
    "                            )\n",
    "        print(\"Generating {n_synthetic_data} samples without conditions\")\n",
    "        condition_list.append(synthetic_data_count)\n",
    "        \n",
    "    #* Synthesizer setup\n",
    "    if synthesizer == \"CTGAN\":\n",
    "        synthesizer = CTGANSynthesizer(\n",
    "                                metadata=metadata, \n",
    "                                enforce_min_max_values=True, \n",
    "                                enforce_rounding=True, \n",
    "                                epochs = epochs,\n",
    "                                verbose=True, \n",
    "                                cuda=True,\n",
    "                                batch_size=batch_size\n",
    "                                )   \n",
    "    elif synthesizer == \"TVAE\":\n",
    "        synthesizer = TVAESynthesizer(\n",
    "                                metadata=metadata, \n",
    "                                enforce_min_max_values=True, \n",
    "                                enforce_rounding=True, \n",
    "                                epochs = epochs,\n",
    "                                verbose=True, \n",
    "                                cuda=True,\n",
    "                                batch_size=batch_size,\n",
    "                                )\n",
    "    synthetic_data = synthesizer.sample_from_conditions(\n",
    "        conditions=condition_list,\n",
    "        output_file_path='./synthetic_dataset/synthetic_data.csv'\n",
    "    )\n",
    "    df_train = pd.concat(synthetic_data, df_train, ignore_index=True)\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "869609c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "def apply_smotenc_oversampling(df_train):\n",
    "    \n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    # Use the original encoded single column name here\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    y_col = 'DR'\n",
    "\n",
    "    print(\"\\nApplying SMOTENC oversampling...\")\n",
    "\n",
    "    # Split features and label\n",
    "    X = df_train.drop(columns=[y_col])\n",
    "    y = df_train[y_col]\n",
    "\n",
    "    # Find indices of categorical features\n",
    "    cat_indices = [X.columns.get_loc(col) for col in cat_cols if col in X.columns]\n",
    "\n",
    "    # Ensure 'Community' is integer type if present\n",
    "    if 'Community' in X.columns:\n",
    "        X['Community'] = X['Community'].astype(int)\n",
    "\n",
    "    oversampler = SMOTENC(categorical_features=cat_indices, random_state=42)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "    print(pd.DataFrame(X_resampled, columns=X.columns).describe())\n",
    "    print(\"\\nFinal class distribution:\", pd.Series(y_resampled).value_counts())\n",
    "\n",
    "    # Recombine into a single DataFrame\n",
    "    df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    df_resampled[y_col] = y_resampled\n",
    "\n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272609da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_one_hot_encoding(df_train, df_test):\n",
    "    community_mapping = {\n",
    "    0: 'Community_baihe', 1: 'Community_chonggu', 2: 'Community_huaxin', 3: 'Community_jinze', 4: 'Community_liantang', 5: 'Community_xianghuaqiao', 6: 'Community_xujin', 7: 'Community_yingpu', 8: 'Community_zhaoxian', 9: 'Community_zhujiajiao'\n",
    "    }\n",
    "    \n",
    "    # Map integer community labels to names\n",
    "    for df in [df_train, df_test]:\n",
    "        if 'Community' in df.columns:\n",
    "            df['Community'] = df['Community'].astype(int).map(community_mapping)\n",
    "\n",
    "    # One-hot encode the 'Community' column\n",
    "    for df in [df_train, df_test]:\n",
    "        if 'Community' in df.columns:\n",
    "            df = pd.get_dummies(df, columns=['Community'], prefix='Community', prefix_sep='_', drop_first=False, dtype=int)\n",
    "\n",
    "    # Align test set to training columns\n",
    "    final_train_cols = df_train.columns\n",
    "\n",
    "    df_test = df_test.reindex(columns=final_train_cols, fill_value=0)\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "def get_bmi(df, df_test):\n",
    "    # Calculate BMI for both training and test sets\n",
    "    df['BMI'] = df['Weight'] / ((df['Height'] / 100) ** 2)\n",
    "    df_test['BMI'] = df_test['Weight'] / ((df_test['Height'] / 100) ** 2)\n",
    "    return df, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f91d2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e291456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FOLDS_GENERATOR(dataset, n_splits=5, random_state=None, \n",
    "                    OD_majority=None, OD_minority=None,\n",
    "                    oversampler_first = True, oversampler=None, \n",
    "                    synthesizer = \"TVAE\", epochs = 200, n_synthetic_data=None, \n",
    "                    scaler=None):\n",
    "    \n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    # Use the original encoded single column name here\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    y_col = 'DR'\n",
    "    \n",
    "    \n",
    "    kF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    kFolds_list = []\n",
    "\n",
    "    # Convert column names to strings to ensure compatibility\n",
    "    df = dataset.copy()\n",
    "    X = df.drop(columns=[\"DR\"])\n",
    "    Y = pd.DataFrame(df[\"DR\"])\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kF.split(X, Y)):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        train = pd.concat([X.iloc[train_idx], Y.iloc[train_idx]], axis=1)\n",
    "        test = pd.concat([X.iloc[test_idx], Y.iloc[test_idx]], axis=1)\n",
    "        \n",
    "        #* OUTLIER DETECTION\n",
    "        X_train_processed = Outlier_Removal(train, \n",
    "                                            OD_majority=OD_majority,\n",
    "                                            OD_minority=OD_minority,\n",
    "                                            )\n",
    "        \n",
    "        #* OVERSAMPLING & SYNTHETIC DATA GENERATION\n",
    "        print(\"Before oversampling & synthetic data:\", X_train_processed[[\"DR\"]].value_counts())\n",
    "        if oversampler_first: \n",
    "            X_train_processed = apply_smotenc_oversampling(X_train_processed)\n",
    "            X_train_processed = Synthetic_Data_Generator(X_train_processed, synthesizer=synthesizer, conditions=\"None\", epochs=epochs, batch_size=512, n_synthetic_data=n_synthetic_data)\n",
    "        else:\n",
    "            X_train_processed = Synthetic_Data_Generator(X_train_processed, synthesizer=synthesizer, conditions=\"None\", epochs=epochs, batch_size=512, n_synthetic_data=None)\n",
    "            X_train_processed = apply_smotenc_oversampling(X_train_processed)\n",
    "        print(\"After oversampling & synthetic data:\", X_train_processed[[\"DR\"]].value_counts())\n",
    "        \n",
    "        #* Calculate BMI & ENCODING\n",
    "        X_train_processed, test = get_bmi(X_train_processed, test)\n",
    "        X_train_processed, test = apply_one_hot_encoding(X_train_processed, test)\n",
    "        #* Scaler\n",
    "        X_train_processed[cont_cols] = scaler.fit_transform(X_train_processed[cont_cols])\n",
    "        test[cont_cols] = scaler.transform(test[cont_cols])\n",
    "        # Append processed data (excluding the target column 'DR')\n",
    "        kFolds_list.append((X_train_processed.drop(columns=[\"DR\"]),\n",
    "                            test.drop(columns=[\"DR\"]),\n",
    "                            X_train_processed[[\"DR\"]],\n",
    "                            test[[\"DR\"]]))\n",
    "\n",
    "        print(f\"Fold: {fold+1}, Train: {X_train_processed.shape}, Test: {test.shape}\")\n",
    "    \n",
    "    return kFolds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcad859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FOLDS_GENERATOR(dataset, n_splits=5, random_state=None, oversampler=None, noise=None,\n",
    "                    OD_majority=None, OD_minority=None, scaler=None):\n",
    "kF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "kFolds_list = []\n",
    "\n",
    "# Convert column names to strings to ensure compatibility\n",
    "df = dataset.copy()\n",
    "X = df.drop(columns=[\"DR\"])\n",
    "Y = pd.DataFrame(df[\"DR\"])\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kF.split(X, Y)):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    train = pd.concat([X.iloc[train_idx], Y.iloc[train_idx]], axis=1)\n",
    "    test = pd.concat([X.iloc[test_idx], Y.iloc[test_idx]], axis=1)\n",
    "    \n",
    "    # Apply Preprocessing to training and test data\n",
    "    X_train_processed, X_test_processed = Outlier_Removal(train, OD_majority, OD_minority)\n",
    "\n",
    "    \n",
    "    = synthetic_data_generation\n",
    "\n",
    "    # Append processed data (excluding the target column 'DR')\n",
    "    kFolds_list.append((X_train_processed.drop(columns=[\"DR\"]),\n",
    "                        X_test_processed.drop(columns=[\"DR\"]),\n",
    "                        X_train_processed[[\"DR\"]],\n",
    "                        X_test_processed[[\"DR\"]]))\n",
    "    \n",
    "    add bmi Column\n",
    "    \n",
    "    print(f\"Fold: {fold+1}, Train: {X_train_processed.shape}, Test: {X_test_processed.shape}\")\n",
    "\n",
    "return kFolds_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
