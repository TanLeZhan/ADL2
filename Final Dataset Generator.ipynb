{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028354d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "from Training_Helper_Functions import *\n",
    "from Preprocessing_Functions2 import * \n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf1922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "import os\n",
    "os.makedirs(\"./DATA/folds\", exist_ok=True)\n",
    "os.makedirs(\"./DATA/holdout_set\", exist_ok=True)\n",
    "os.makedirs(\"./DATA/synthetic_training_set\", exist_ok=True)\n",
    "os.makedirs(\"./DATA/training_set\", exist_ok=True)\n",
    "# Load and split dataset\n",
    "data = pd.read_csv(\"./original_dataset/processed_data_encoded.csv\")\n",
    "X = data.drop(columns=[\"DR\"])  # Keep BMI and TCTG if you're removing them later\n",
    "Y = data[\"DR\"]\n",
    "\n",
    "X_folds, X_test, Y_folds, Y_test = train_test_split(X, Y, test_size=0.1, stratify=Y, random_state=random_state)\n",
    "\n",
    "# Save training and holdout sets\n",
    "pd.concat([X_folds, Y_folds], axis=1).reset_index(drop=True).to_csv(\"./DATA/training_set/training_data.csv\", index=False)\n",
    "pd.concat([X_test, Y_test], axis=1).reset_index(drop=True).to_csv(\"./DATA/holdout_set/holdout_data.csv\", index=False)\n",
    "\n",
    "# Apply encoding\n",
    "df_train, df_test = apply_one_hot_encoding(\n",
    "    pd.concat([X_folds, Y_folds], axis=1).reset_index(drop=True),\n",
    "    pd.concat([X_test, Y_test], axis=1).reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_test.to_csv(\"./DATA/holdout_set/holdout_data_OHE.csv\", index=False) #only do OHE for holdout set for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58ec440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Outlier_Removal(df_train, OD_majority, OD_minority): \n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    # Use the original encoded single column name here\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    y_col = 'DR'\n",
    "\n",
    "    print(\"Original class distribution:\",df_train[y_col].value_counts())\n",
    "    assert y_col in df_train.columns, f\"'{y_col}' column is missing in the DataFrame.\"\n",
    "    \n",
    "    #* OUTLIER DETECTION START\n",
    "    available_cont_cols = [col for col in cont_cols if col in df_train.columns]\n",
    "    df_majority = df_train[df_train[y_col] == 0].copy()\n",
    "    df_minority = df_train[df_train[y_col] == 1].copy()\n",
    "    if OD_majority is not None:\n",
    "        outliers_majority = OD_majority.fit_predict(df_majority[available_cont_cols])\n",
    "        df_majority = df_majority[outliers_majority == 1]\n",
    "        print(f\"After OD, majority: {len(df_majority)}\")\n",
    "    if OD_minority is not None:\n",
    "        outliers_minority = OD_minority.fit_predict(df_minority[available_cont_cols])\n",
    "        df_minority = df_minority[outliers_minority == 1]\n",
    "        print(f\"After OD, minority: {len(df_minority)}\")\n",
    "    df_after_OD = pd.concat([df_majority, df_minority], ignore_index=True)\n",
    "    #* OUTLIER DETECTION END - df_after_OD is the new df\n",
    "    return df_after_OD\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "def apply_smotenc_oversampling(df_train):\n",
    "    \n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    # Use the original encoded single column name here\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    y_col = 'DR'\n",
    "\n",
    "    print(\"\\nApplying SMOTENC oversampling...\")\n",
    "\n",
    "    # Split features and label\n",
    "    X = df_train.drop(columns=[y_col])\n",
    "    y = df_train[y_col]\n",
    "\n",
    "    # Find indices of categorical features\n",
    "    cat_indices = [X.columns.get_loc(col) for col in cat_cols if col in X.columns]\n",
    "\n",
    "    # Ensure 'Community' is integer type if present\n",
    "    if 'Community' in X.columns:\n",
    "        X['Community'] = X['Community'].astype(int)\n",
    "\n",
    "    oversampler = SMOTENC(categorical_features=cat_indices, random_state=42)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "    print(pd.DataFrame(X_resampled, columns=X.columns).describe())\n",
    "    print(\"\\nFinal class distribution:\", pd.Series(y_resampled).value_counts())\n",
    "\n",
    "    # Recombine into a single DataFrame\n",
    "    df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    df_resampled[y_col] = y_resampled\n",
    "\n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def FOLDS_GENERATOR1(df:pd.DataFrame, n_splits=5, random_state=42, OD_majority=None, OD_minority=None,\n",
    "                    synthesizer = \"TVAE\", epochs = 100, batch_size=512, n_synthetic_data=0,\n",
    "                    scaler=None):\n",
    "    \"\"\"\n",
    "    Generates n_splits folds for cross-validation.\n",
    "    \"\"\"\n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    # Create a StratifiedKFold object\n",
    "    kF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    # Initialize a list to hold the folds\n",
    "    df_copy = df.copy()\n",
    "    X = df_copy.drop(columns=[\"DR\"])\n",
    "    Y = df[[\"DR\"]]\n",
    "    X = X.drop(columns=[\"BMI\", \"TCTG\"])\n",
    "\n",
    "    kFolds_list = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(kF.split(X, Y)):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        train = pd.concat([X.iloc[train_idx], Y.iloc[train_idx]], axis=1)\n",
    "        test = pd.concat([X.iloc[test_idx], Y.iloc[test_idx]], axis=1)\n",
    "        \n",
    "        # #* OUTLIER DETECTION\n",
    "        X_train_processed = Outlier_Removal(train, \n",
    "                                            OD_majority=OD_majority,\n",
    "                                            OD_minority=OD_minority,\n",
    "                                            )\n",
    "        \n",
    "        # #* OVERSAMPLING & SYNTHETIC DATA GENERATION\n",
    "        print(\"Before oversampling & synthetic data:\", X_train_processed[[\"DR\"]].value_counts())\n",
    "        X_train_processed = Synthetic_Data_Generator2(X_train_processed, fold, synthesizer=synthesizer, epochs=epochs, batch_size=512, n_synthetic_data=n_synthetic_data)\n",
    "        # X_train_processed = apply_smotenc_oversampling(X_train_processed)\n",
    "        \n",
    "        print(\"After oversampling & synthetic data:\", X_train_processed[[\"DR\"]].value_counts())\n",
    "        X_train_processed = train.copy()\n",
    "        \n",
    "        #* Calculate BMI, TCTG & ENCODING\n",
    "        X_train_processed, test = get_bmi(X_train_processed, test)\n",
    "        X_train_processed, test = get_TCTG(X_train_processed, test)\n",
    "        X_train_processed, test = apply_one_hot_encoding(X_train_processed, test)\n",
    "        #* Scaler\n",
    "        X_train_processed[cont_cols] = scaler.fit_transform(X_train_processed[cont_cols])\n",
    "        test[cont_cols] = scaler.transform(test[cont_cols])\n",
    "        # Append processed data (excluding the target column 'DR')\n",
    "\n",
    "        # Save to CSV with fold number\n",
    "        X_train_processed.to_csv(f\"./DATA/folds/train_fold_{fold}.csv\", index=False)\n",
    "        test.to_csv(f\"./DATA/folds/test_fold_{fold}.csv\", index=False)\n",
    "        kFolds_list.append((\n",
    "                            X_train_processed.drop(columns=['DR']),\n",
    "                            test.drop(columns=['DR']),\n",
    "                            X_train_processed['DR'].values.reshape(-1, 1),  # Ensures the target is 2D\n",
    "                            test['DR'].values.reshape(-1, 1)  # Ensures the target is 2D\n",
    "                        ))\n",
    "        break\n",
    "    print(f\"Fold: {fold+1}, Train: {X_train_processed.drop(columns=['DR']).shape}, Test: {test.drop(columns=['DR']).shape}\")\n",
    "    \n",
    "    return kFolds_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68320b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 2136\n",
      "After OD, minority: 355\n",
      "Before oversampling & synthetic data: DR \n",
      "0.0    2136\n",
      "1.0     355\n",
      "Name: count, dtype: int64\n",
      "Fitting synthesizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub repos\\ADL2\\.venv\\Lib\\site-packages\\sdv\\single_table\\base.py:105: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
      "  warnings.warn(\n",
      "  File \"d:\\GitHub repos\\ADL2\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import standardscaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = RobustScaler()\n",
    "scaler = StandardScaler()\n",
    "training_set = pd.read_csv(\"./DATA/training_set/training_data.csv\")\n",
    "\n",
    "kFolds = FOLDS_GENERATOR1(training_set, n_splits=5, random_state=42,             \n",
    "                            OD_majority = IQRDetector(factor=1),\n",
    "                            OD_minority = IQRDetector(factor=2),\n",
    "                            synthesizer = \"TVAE\",\n",
    "                            epochs = 1000,\n",
    "                            n_synthetic_data = 10000,\n",
    "                            scaler=scaler,      \n",
    "                            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe1b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa605a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
