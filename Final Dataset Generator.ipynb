{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028354d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "from Training_Helper_Functions import *\n",
    "from Preprocessing_Functions2 import * \n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf1922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "import os\n",
    "os.makedirs(\"./DATA/folds\", exist_ok=True)\n",
    "os.makedirs(\"./DATA/holdout_set\", exist_ok=True)\n",
    "os.makedirs(\"./DATA/synthetic_training_set\", exist_ok=True)\n",
    "os.makedirs(\"./DATA/training_set\", exist_ok=True)\n",
    "# Load and split dataset\n",
    "data = pd.read_csv(\"./original_dataset/processed_data_encoded.csv\")\n",
    "X = data.drop(columns=[\"DR\"])  # Keep BMI and TCTG if you're removing them later\n",
    "Y = data[\"DR\"]\n",
    "\n",
    "X_folds, X_test, Y_folds, Y_test = train_test_split(X, Y, test_size=0.1, stratify=Y, random_state=random_state)\n",
    "\n",
    "# Save training and holdout sets\n",
    "pd.concat([X_folds, Y_folds], axis=1).reset_index(drop=True).to_csv(\"./DATA/training_set/training_data.csv\", index=False)\n",
    "pd.concat([X_test, Y_test], axis=1).reset_index(drop=True).to_csv(\"./DATA/holdout_set/holdout_data.csv\", index=False)\n",
    "\n",
    "# Apply encoding\n",
    "df_train, df_test = apply_one_hot_encoding(\n",
    "    pd.concat([X_folds, Y_folds], axis=1).reset_index(drop=True),\n",
    "    pd.concat([X_test, Y_test], axis=1).reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_test.to_csv(\"./DATA/holdout_set/holdout_data_OHE.csv\", index=False) #only do OHE for holdout set for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58ec440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Outlier_Removal(df_train, OD_majority, OD_minority): \n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    # Use the original encoded single column name here\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    y_col = 'DR'\n",
    "\n",
    "    print(\"Original class distribution:\",df_train[y_col].value_counts())\n",
    "    assert y_col in df_train.columns, f\"'{y_col}' column is missing in the DataFrame.\"\n",
    "    \n",
    "    #* OUTLIER DETECTION START\n",
    "    available_cont_cols = [col for col in cont_cols if col in df_train.columns]\n",
    "    df_majority = df_train[df_train[y_col] == 0].copy()\n",
    "    df_minority = df_train[df_train[y_col] == 1].copy()\n",
    "    if OD_majority is not None:\n",
    "        outliers_majority = OD_majority.fit_predict(df_majority[available_cont_cols])\n",
    "        df_majority = df_majority[outliers_majority == 1]\n",
    "        print(f\"After OD, majority: {len(df_majority)}\")\n",
    "    if OD_minority is not None:\n",
    "        outliers_minority = OD_minority.fit_predict(df_minority[available_cont_cols])\n",
    "        df_minority = df_minority[outliers_minority == 1]\n",
    "        print(f\"After OD, minority: {len(df_minority)}\")\n",
    "    df_after_OD = pd.concat([df_majority, df_minority], ignore_index=True)\n",
    "    #* OUTLIER DETECTION END - df_after_OD is the new df\n",
    "    return df_after_OD\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "def apply_smotenc_oversampling(df_train):\n",
    "    \n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    # Use the original encoded single column name here\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    y_col = 'DR'\n",
    "\n",
    "    print(\"\\nApplying SMOTENC oversampling...\")\n",
    "\n",
    "    # Split features and label\n",
    "    X = df_train.drop(columns=[y_col])\n",
    "    y = df_train[y_col]\n",
    "\n",
    "    # Find indices of categorical features\n",
    "    cat_indices = [X.columns.get_loc(col) for col in cat_cols if col in X.columns]\n",
    "\n",
    "    # Ensure 'Community' is integer type if present\n",
    "    if 'Community' in X.columns:\n",
    "        X['Community'] = X['Community'].astype(int)\n",
    "\n",
    "    oversampler = SMOTENC(categorical_features=cat_indices, random_state=42)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "    print(pd.DataFrame(X_resampled, columns=X.columns).describe())\n",
    "    print(\"\\nFinal class distribution:\", pd.Series(y_resampled).value_counts())\n",
    "\n",
    "    # Recombine into a single DataFrame\n",
    "    df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    df_resampled[y_col] = y_resampled\n",
    "\n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def FOLDS_GENERATOR1(df:pd.DataFrame, n_splits=5, random_state=42, OD_majority=None, OD_minority=None,\n",
    "                    synthesizer = \"TVAE\", epochs = 100, batch_size=512, n_synthetic_data=0,\n",
    "                    scaler=None):\n",
    "    \"\"\"\n",
    "    Generates n_splits folds for cross-validation.\n",
    "    \"\"\"\n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    # Create a StratifiedKFold object\n",
    "    kF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    # Initialize a list to hold the folds\n",
    "    df_copy = df.copy()\n",
    "    X = df_copy.drop(columns=[\"DR\"])\n",
    "    Y = df[[\"DR\"]]\n",
    "    X = X.drop(columns=[\"BMI\", \"TCTG\"])\n",
    "\n",
    "    kFolds_list = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(kF.split(X, Y)):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        train = pd.concat([X.iloc[train_idx], Y.iloc[train_idx]], axis=1)\n",
    "        test = pd.concat([X.iloc[test_idx], Y.iloc[test_idx]], axis=1)\n",
    "        \n",
    "        # #* OUTLIER DETECTION\n",
    "        X_train_processed = Outlier_Removal(train, \n",
    "                                            OD_majority=OD_majority,\n",
    "                                            OD_minority=OD_minority,\n",
    "                                            )\n",
    "        X_train_processed = apply_smotenc_oversampling(X_train_processed)\n",
    "        # # #* OVERSAMPLING & SYNTHETIC DATA GENERATION\n",
    "        # print(\"Before oversampling & synthetic data:\", X_train_processed[[\"DR\"]].value_counts())\n",
    "        # X_train_processed = Synthetic_Data_Generator(X_train_processed, fold, synthesizer=synthesizer, epochs=epochs, batch_size=512, n_synthetic_data=n_synthetic_data)\n",
    "        \n",
    "        \n",
    "        # print(\"After oversampling & synthetic data:\", X_train_processed[[\"DR\"]].value_counts())\n",
    "\n",
    "        \n",
    "        #* Calculate BMI, TCTG & ENCODING\n",
    "        X_train_processed, test = get_bmi(X_train_processed, test)\n",
    "        X_train_processed, test = get_TCTG(X_train_processed, test)\n",
    "        X_train_processed, test = apply_one_hot_encoding(X_train_processed, test)\n",
    "        #* Scaler\n",
    "        X_train_processed[cont_cols] = scaler.fit_transform(X_train_processed[cont_cols])\n",
    "        test[cont_cols] = scaler.transform(test[cont_cols])\n",
    "        # Append processed data (excluding the target column 'DR')\n",
    "\n",
    "        # Save to CSV with fold number\n",
    "        X_train_processed.to_csv(f\"./DATA/folds/train_fold_{fold}.csv\", index=False)\n",
    "        test.to_csv(f\"./DATA/folds/test_fold_{fold}.csv\", index=False)\n",
    "        kFolds_list.append((\n",
    "                            X_train_processed.drop(columns=['DR']),\n",
    "                            test.drop(columns=['DR']),\n",
    "                            X_train_processed['DR'].values.reshape(-1, 1),  # Ensures the target is 2D\n",
    "                            test['DR'].values.reshape(-1, 1)  # Ensures the target is 2D\n",
    "                        ))\n",
    "        break\n",
    "    print(f\"Fold: {fold+1}, Train: {X_train_processed.drop(columns=['DR']).shape}, Test: {test.drop(columns=['DR']).shape}\")\n",
    "    \n",
    "    return kFolds_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e68320b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 2842\n",
      "After OD, minority: 377\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "               Age       Gender    Community         UAlb           Ucr  \\\n",
      "count  5684.000000  5684.000000  5684.000000  5684.000000   5684.000000   \n",
      "mean     63.427669     0.528853     4.040992    18.563065   3743.499853   \n",
      "std       6.888182     0.499211     3.091013    24.835487   5357.826033   \n",
      "min      36.000000     0.000000     0.000000     0.100000      1.000000   \n",
      "25%      59.000000     0.000000     1.000000     4.700000      6.000000   \n",
      "50%      63.774894     1.000000     4.000000     9.700000     11.000000   \n",
      "75%      68.000000     1.000000     7.000000    20.793206   7164.250000   \n",
      "max      87.000000     1.000000     9.000000   174.800000  21612.000000   \n",
      "\n",
      "              UACR           TC           TG         LDLC         HDLC  \\\n",
      "count  5684.000000  5684.000000  5684.000000  5684.000000  5684.000000   \n",
      "mean     20.195918     5.235812     1.446538     3.234609     1.356345   \n",
      "std      26.482991     0.911567     0.718309     0.815320     0.268084   \n",
      "min       0.100000     2.620000     0.110000     0.700000     0.600000   \n",
      "25%       5.600000     4.610000     0.920000     2.688777     1.160000   \n",
      "50%      10.800000     5.220000     1.280000     3.240000     1.329913   \n",
      "75%      23.669395     5.820677     1.820000     3.750000     1.520000   \n",
      "max     211.100000     9.280000     4.260000     6.520000     2.610000   \n",
      "\n",
      "               Scr          BUN          FPG        HbA1c       Height  \\\n",
      "count  5684.000000  5684.000000  5684.000000  5684.000000  5684.000000   \n",
      "mean     59.088910     5.898123     9.223628     7.461459   161.535682   \n",
      "std      13.173174     1.362692     2.484465     1.334170     7.208863   \n",
      "min      28.000000     2.100000     4.200000     4.300000   138.000000   \n",
      "25%      49.307498     4.952635     7.500000     6.500000   156.000000   \n",
      "50%      58.000000     5.700000     8.800000     7.259241   161.000000   \n",
      "75%      67.000000     6.700000    10.536898     8.300000   167.000000   \n",
      "max     108.000000    12.000000    20.500000    13.700000   185.000000   \n",
      "\n",
      "            Weight     Duration  \n",
      "count  5684.000000  5684.000000  \n",
      "mean     63.441661     8.630701  \n",
      "std       8.877216     5.746448  \n",
      "min      37.000000     0.100000  \n",
      "25%      57.000000     3.900000  \n",
      "50%      63.000000     7.673599  \n",
      "75%      70.000000    13.000000  \n",
      "max      98.000000    33.000000  \n",
      "\n",
      "Final class distribution: DR\n",
      "0.0    2842\n",
      "1.0    2842\n",
      "Name: count, dtype: int64\n",
      "Fold: 1, Train: (5684, 28), Test: (1149, 28)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import standardscaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = RobustScaler()\n",
    "scaler = StandardScaler()\n",
    "training_set = pd.read_csv(\"./DATA/training_set/training_data.csv\")\n",
    "\n",
    "kFolds = FOLDS_GENERATOR1(training_set, n_splits=5, random_state=42,             \n",
    "                            OD_majority = IQRDetector(factor=1.5),\n",
    "                            # OD_minority = IsolationForest(contamination=0.015, random_state=42),\n",
    "                            OD_minority = IQRDetector(factor=2.5),\n",
    "                            synthesizer = \"CTGAN\",\n",
    "                            epochs = 1000,\n",
    "                            n_synthetic_data = 10000,\n",
    "                            scaler=scaler,      \n",
    "                            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe1b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa605a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
