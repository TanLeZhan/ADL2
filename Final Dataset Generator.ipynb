{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "028354d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training_Helper_Functions import *\n",
    "from Preprocessing_Functions2 import * \n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "import os\n",
    "os.makedirs(\"./DATA/folds\", exist_ok=True)\n",
    "os.makedirs(\"./DATA/holdout_set\", exist_ok=True)\n",
    "os.makedirs(\"./DATA/synthetic_training_set\", exist_ok=True)\n",
    "os.makedirs(\"./DATA/training_set\", exist_ok=True)\n",
    "# Load and split dataset\n",
    "data = pd.read_csv(\"./original_dataset/processed_data_encoded.csv\")\n",
    "X = data.drop(columns=[\"DR\"])  # Keep BMI and TCTG if you're removing them later\n",
    "Y = data[\"DR\"]\n",
    "\n",
    "X_folds, X_test, Y_folds, Y_test = train_test_split(X, Y, test_size=0.1, stratify=Y, random_state=random_state)\n",
    "\n",
    "# Save training and holdout sets\n",
    "pd.concat([X_folds, Y_folds], axis=1).reset_index(drop=True).to_csv(\"./DATA/training_set/training_data.csv\", index=False)\n",
    "pd.concat([X_test, Y_test], axis=1).reset_index(drop=True).to_csv(\"./DATA/holdout_set/holdout_data.csv\", index=False)\n",
    "\n",
    "# Apply encoding\n",
    "df_train, df_test = apply_one_hot_encoding(\n",
    "    pd.concat([X_folds, Y_folds], axis=1).reset_index(drop=True),\n",
    "    pd.concat([X_test, Y_test], axis=1).reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_test.to_csv(\"./DATA/holdout_set/holdout_data_OHE.csv\", index=False) #only do OHE for holdout set for now\n",
    "df_train.to_csv(\"./DATA/training_set/training_data_OHE.csv\", index=False)\n",
    "data_OHE = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58ec440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Outlier_Removal(df_train, OD_majority, OD_minority): \n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    # Use the original encoded single column name here\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    y_col = 'DR'\n",
    "\n",
    "    print(\"Original class distribution:\",df_train[y_col].value_counts())\n",
    "    assert y_col in df_train.columns, f\"'{y_col}' column is missing in the DataFrame.\"\n",
    "    \n",
    "    #* OUTLIER DETECTION START\n",
    "    available_cont_cols = [col for col in cont_cols if col in df_train.columns]\n",
    "    df_majority = df_train[df_train[y_col] == 0].copy()\n",
    "    df_minority = df_train[df_train[y_col] == 1].copy()\n",
    "    if OD_majority is not None:\n",
    "        outliers_majority = OD_majority.fit_predict(df_majority[available_cont_cols])\n",
    "        df_majority = df_majority[outliers_majority == 1]\n",
    "        print(f\"After OD, majority: {len(df_majority)}\")\n",
    "    if OD_minority is not None:\n",
    "        outliers_minority = OD_minority.fit_predict(df_minority[available_cont_cols])\n",
    "        df_minority = df_minority[outliers_minority == 1]\n",
    "        print(f\"After OD, minority: {len(df_minority)}\")\n",
    "    df_after_OD = pd.concat([df_majority, df_minority], ignore_index=True)\n",
    "    #* OUTLIER DETECTION END - df_after_OD is the new df\n",
    "    return df_after_OD\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "def apply_smotenc_oversampling(df_train):\n",
    "    \n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    # Use the original encoded single column name here\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    y_col = 'DR'\n",
    "\n",
    "    print(\"\\nApplying SMOTENC oversampling...\")\n",
    "\n",
    "    # Split features and label\n",
    "    X = df_train.drop(columns=[y_col])\n",
    "    y = df_train[y_col]\n",
    "\n",
    "    # Find indices of categorical features\n",
    "    cat_indices = [X.columns.get_loc(col) for col in cat_cols if col in X.columns]\n",
    "\n",
    "    # Ensure 'Community' is integer type if present\n",
    "    if 'Community' in X.columns:\n",
    "        X['Community'] = X['Community'].astype(int)\n",
    "\n",
    "    oversampler = SMOTENC(categorical_features=cat_indices, random_state=42)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "    print(pd.DataFrame(X_resampled, columns=X.columns).describe())\n",
    "    print(\"\\nFinal class distribution:\", pd.Series(y_resampled).value_counts())\n",
    "\n",
    "    # Recombine into a single DataFrame\n",
    "    df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    df_resampled[y_col] = y_resampled\n",
    "\n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def FOLDS_GENERATOR1(df:pd.DataFrame, n_splits=5, random_state=42, OD_majority=None, OD_minority=None,\n",
    "                    synthesizer = \"TVAE\", epochs = 100, batch_size=512, n_synthetic_data=0,\n",
    "                    scaler=None):\n",
    "    \"\"\"\n",
    "    Generates n_splits folds for cross-validation.\n",
    "    \"\"\"\n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    # Create a StratifiedKFold object\n",
    "    kF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    # Initialize a list to hold the folds\n",
    "    df_copy = df.copy()\n",
    "    X = df_copy.drop(columns=[\"DR\"])\n",
    "    Y = df[[\"DR\"]]\n",
    "    X = X.drop(columns=[\"BMI\", \"TCTG\"])\n",
    "\n",
    "    kFolds_list = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(kF.split(X, Y)):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        train = pd.concat([X.iloc[train_idx], Y.iloc[train_idx]], axis=1)\n",
    "        test = pd.concat([X.iloc[test_idx], Y.iloc[test_idx]], axis=1)\n",
    "        \n",
    "        # # #* OUTLIER DETECTION\n",
    "        # X_train_processed = Outlier_Removal(train, \n",
    "        #                                     OD_majority=OD_majority,\n",
    "        #                                     OD_minority=OD_minority,\n",
    "        #                                     )\n",
    "        # X_train_processed = apply_smotenc_oversampling(X_train_processed)\n",
    "        X_train_processed = train.copy()\n",
    "        # #* OVERSAMPLING & SYNTHETIC DATA GENERATION\n",
    "        print(\"Before oversampling & synthetic data:\", X_train_processed[[\"DR\"]].value_counts())\n",
    "        X_train_processed = Synthetic_Data_Generator2(X_train_processed, fold, synthesizer=synthesizer, epochs=epochs, batch_size=256, n_synthetic_data=n_synthetic_data)\n",
    "        # X_train_processed = Outlier_Removal(train, \n",
    "        #                                     OD_majority=OD_majority,\n",
    "        #                                     OD_minority=OD_minority,\n",
    "        #                                     )\n",
    "        #\n",
    "        X_train_processed = Outlier_Removal(X_train_processed, \n",
    "                                            OD_majority=OD_majority,\n",
    "                                            OD_minority=OD_minority,\n",
    "                                            )\n",
    "        X_train_processed = apply_smotenc_oversampling(X_train_processed)\n",
    "        \n",
    "        print(\"After oversampling & synthetic data:\", X_train_processed[[\"DR\"]].value_counts())\n",
    "\n",
    "        \n",
    "        #* Calculate BMI, TCTG & ENCODING\n",
    "        X_train_processed, test = get_bmi(X_train_processed, test)\n",
    "        X_train_processed, test = get_TCTG(X_train_processed, test)\n",
    "        X_train_processed, test = apply_one_hot_encoding(X_train_processed, test)\n",
    "        #* Scaler\n",
    "        X_train_processed[cont_cols] = scaler.fit_transform(X_train_processed[cont_cols])\n",
    "        test[cont_cols] = scaler.transform(test[cont_cols])\n",
    "        # Append processed data (excluding the target column 'DR')\n",
    "\n",
    "        # Save to CSV with fold number\n",
    "        X_train_processed.to_csv(f\"./DATA/folds/train_fold_{fold}.csv\", index=False)\n",
    "        test.to_csv(f\"./DATA/folds/test_fold_{fold}.csv\", index=False)\n",
    "        kFolds_list.append((\n",
    "                            X_train_processed.drop(columns=['DR']),\n",
    "                            test.drop(columns=['DR']),\n",
    "                            X_train_processed['DR'].values.reshape(-1, 1),  # Ensures the target is 2D\n",
    "                            test['DR'].values.reshape(-1, 1)  # Ensures the target is 2D\n",
    "                        ))\n",
    "        break\n",
    "    print(f\"Fold: {fold+1}, Train: {X_train_processed.drop(columns=['DR']).shape}, Test: {test.drop(columns=['DR']).shape}\")\n",
    "    \n",
    "    return kFolds_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e68320b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling & synthetic data: DR \n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "Fitting synthesizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub repos\\ADL2\\.venv\\Lib\\site-packages\\sdv\\single_table\\base.py:105: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
      "  warnings.warn(\n",
      "Loss: -11.901: 100%|██████████| 1000/1000 [14:19<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic samples per class based on distribution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|██████████| 8989/8989 [00:01<00:00, 5888.22it/s]\n",
      "Sampling conditions: 100%|██████████| 1010/1010 [00:04<00:00, 220.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final synthetic class distribution:\n",
      "DR\n",
      "0.0    8989\n",
      "1.0    1010\n",
      "Name: count, dtype: int64\n",
      "Generating report ...\n",
      "\n",
      "(1/2) Evaluating Column Shapes: |██████████| 18/18 [00:05<00:00,  3.19it/s]|\n",
      "Column Shapes Score: 91.55%\n",
      "\n",
      "(2/2) Evaluating Column Pair Trends: |██████████| 153/153 [00:02<00:00, 59.99it/s]|\n",
      "Column Pair Trends Score: 89.15%\n",
      "\n",
      "Overall Score (Average): 90.35%\n",
      "\n",
      "Original class distribution: DR\n",
      "0.0    13118\n",
      "1.0     1474\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 9066\n",
      "After OD, minority: 787\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "                Age        Gender     Community          UAlb           Ucr  \\\n",
      "count  18132.000000  18132.000000  18132.000000  18132.000000  18132.000000   \n",
      "mean      63.840973      0.606607      4.965641     17.060560   2339.204993   \n",
      "std        7.712892      0.488516      3.269702     19.656990   4615.881680   \n",
      "min       38.000000      0.000000      0.000000      0.100000      0.000000   \n",
      "25%       58.000000      0.000000      2.000000      4.774726      5.000000   \n",
      "50%       64.000000      1.000000      6.000000     10.479573     10.394748   \n",
      "75%       69.451239      1.000000      8.000000     21.943590    123.000000   \n",
      "max       88.000000      1.000000      9.000000    150.900000  21612.000000   \n",
      "\n",
      "               UACR            TC            TG          LDLC          HDLC  \\\n",
      "count  18132.000000  18132.000000  18132.000000  18132.000000  18132.000000   \n",
      "mean      21.037262      5.216217      1.323305      3.188761      1.419127   \n",
      "std       23.777470      0.764009      0.640100      0.685775      0.315959   \n",
      "min        0.100000      2.860000      0.100000      1.000000      0.600000   \n",
      "25%        6.200000      4.704990      0.854524      2.720000      1.180000   \n",
      "50%       13.255951      5.207910      1.170000      3.200789      1.398849   \n",
      "75%       27.507634      5.706734      1.650000      3.650000      1.650000   \n",
      "max      161.800000      7.770000      3.720000      5.450000      2.590000   \n",
      "\n",
      "                Scr           BUN           FPG         HbA1c        Height  \\\n",
      "count  18132.000000  18132.000000  18132.000000  18132.000000  18132.000000   \n",
      "mean      55.982835      6.101940     10.293487      7.932653    160.577547   \n",
      "std       11.548731      1.242701      2.972824      1.564921      6.982037   \n",
      "min       29.000000      2.400000      4.100000      4.100000    140.000000   \n",
      "25%       47.000000      5.200000      7.900000      6.700000    156.000000   \n",
      "50%       54.899087      6.100000      9.900000      7.800000    160.000000   \n",
      "75%       63.000000      6.954419     12.300000      8.934204    165.429996   \n",
      "max       94.000000     10.300000     21.200000     13.500000    184.000000   \n",
      "\n",
      "             Weight      Duration  \n",
      "count  18132.000000  18132.000000  \n",
      "mean      60.739617      9.330329  \n",
      "std        7.785821      7.107449  \n",
      "min       40.000000      0.100000  \n",
      "25%       55.236941      2.200000  \n",
      "50%       60.300000      8.091778  \n",
      "75%       65.100000     14.942923  \n",
      "max       84.400000     31.000000  \n",
      "\n",
      "Final class distribution: DR\n",
      "0.0    9066\n",
      "1.0    9066\n",
      "Name: count, dtype: int64\n",
      "After oversampling & synthetic data: DR \n",
      "0.0    9066\n",
      "1.0    9066\n",
      "Name: count, dtype: int64\n",
      "Fold: 1, Train: (18132, 28), Test: (1149, 28)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import standardscaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = RobustScaler()\n",
    "scaler = StandardScaler()\n",
    "training_set = pd.read_csv(\"./DATA/training_set/training_data.csv\")\n",
    "\n",
    "kFolds = FOLDS_GENERATOR1(training_set, n_splits=5, random_state=42,             \n",
    "                            OD_majority = IQRDetector(factor=1.5),\n",
    "                            # OD_minority = IsolationForest(contamination=0.015, random_state=42),\n",
    "                            OD_minority = IQRDetector(factor=1.5),\n",
    "                            synthesizer = \"TVAE\",\n",
    "                            epochs = 1000,\n",
    "                            n_synthetic_data = 10000,\n",
    "                            scaler=scaler,      \n",
    "                            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe1b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa605a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
